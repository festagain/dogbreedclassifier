{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:15.559592Z",
     "start_time": "2025-10-08T15:42:14.954846Z"
    }
   },
   "source": [
    "import kagglehub\n",
    "from sklearn.utils.validation import validate_data\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jessicali9530/stanford-dogs-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\festa\\.cache\\kagglehub\\datasets\\jessicali9530\\stanford-dogs-dataset\\versions\\2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:15.569607Z",
     "start_time": "2025-10-08T15:42:15.565605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import pandas as pd\n",
    "def fix_seed(seed = 39):\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  generator = torch.Generator().manual_seed(seed)\n",
    "  return generator\n",
    "generator = fix_seed()\n",
    "path = os.path.join(path, \"images\",\"Images\")\n",
    "print(path)"
   ],
   "id": "44c664225f01b6a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\festa\\.cache\\kagglehub\\datasets\\jessicali9530\\stanford-dogs-dataset\\versions\\2\\images\\Images\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:16.200226Z",
     "start_time": "2025-10-08T15:42:16.174718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "1b5f70255f39cc1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:17.616131Z",
     "start_time": "2025-10-08T15:42:17.611890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_folders = sorted([d for d in os.listdir(self.root_dir) if os.path.isdir(os.path.join(self.root_dir, d))])\n",
    "        self.class_to_idx = {cls : idx for idx, cls in enumerate(self.class_folders)}\n",
    "        self.idx_to_class = {idx: '_'.join(cls.split('-')[1:]).capitalize() for idx, cls in enumerate(self.class_folders)}\n",
    "        self.samples = []\n",
    "        for class_name in self.class_folders:\n",
    "            class_path = os.path.join(self.root_dir, class_name)\n",
    "            for fname in os.listdir(class_path):\n",
    "                if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    img_path = os.path.join(class_path, fname)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = PIL.Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "id": "8974543e3869c219",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:17.965824Z",
     "start_time": "2025-10-08T15:42:17.961829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    T.RandomRotation(20),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "fd338396d4514dfd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:18.614840Z",
     "start_time": "2025-10-08T15:42:18.375980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "full_dataset = CustomDataset(root_dir=path, transform=train_transforms)\n",
    "mapping = full_dataset.idx_to_class\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "other_size = len(full_dataset) - train_size\n",
    "train_dataset, other_dataset = random_split(full_dataset, [train_size, other_size])\n",
    "valid_size = int(0.5 * len(other_dataset))\n",
    "test_size = len(other_dataset) - valid_size\n",
    "valid_dataset, test_dataset = random_split(other_dataset, [valid_size, test_size])\n",
    "mapping"
   ],
   "id": "2dcbea7dc33f4ea8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Chihuahua',\n",
       " 1: 'Japanese_spaniel',\n",
       " 2: 'Maltese_dog',\n",
       " 3: 'Pekinese',\n",
       " 4: 'Shih_tzu',\n",
       " 5: 'Blenheim_spaniel',\n",
       " 6: 'Papillon',\n",
       " 7: 'Toy_terrier',\n",
       " 8: 'Rhodesian_ridgeback',\n",
       " 9: 'Afghan_hound',\n",
       " 10: 'Basset',\n",
       " 11: 'Beagle',\n",
       " 12: 'Bloodhound',\n",
       " 13: 'Bluetick',\n",
       " 14: 'Black_and_tan_coonhound',\n",
       " 15: 'Walker_hound',\n",
       " 16: 'English_foxhound',\n",
       " 17: 'Redbone',\n",
       " 18: 'Borzoi',\n",
       " 19: 'Irish_wolfhound',\n",
       " 20: 'Italian_greyhound',\n",
       " 21: 'Whippet',\n",
       " 22: 'Ibizan_hound',\n",
       " 23: 'Norwegian_elkhound',\n",
       " 24: 'Otterhound',\n",
       " 25: 'Saluki',\n",
       " 26: 'Scottish_deerhound',\n",
       " 27: 'Weimaraner',\n",
       " 28: 'Staffordshire_bullterrier',\n",
       " 29: 'American_staffordshire_terrier',\n",
       " 30: 'Bedlington_terrier',\n",
       " 31: 'Border_terrier',\n",
       " 32: 'Kerry_blue_terrier',\n",
       " 33: 'Irish_terrier',\n",
       " 34: 'Norfolk_terrier',\n",
       " 35: 'Norwich_terrier',\n",
       " 36: 'Yorkshire_terrier',\n",
       " 37: 'Wire_haired_fox_terrier',\n",
       " 38: 'Lakeland_terrier',\n",
       " 39: 'Sealyham_terrier',\n",
       " 40: 'Airedale',\n",
       " 41: 'Cairn',\n",
       " 42: 'Australian_terrier',\n",
       " 43: 'Dandie_dinmont',\n",
       " 44: 'Boston_bull',\n",
       " 45: 'Miniature_schnauzer',\n",
       " 46: 'Giant_schnauzer',\n",
       " 47: 'Standard_schnauzer',\n",
       " 48: 'Scotch_terrier',\n",
       " 49: 'Tibetan_terrier',\n",
       " 50: 'Silky_terrier',\n",
       " 51: 'Soft_coated_wheaten_terrier',\n",
       " 52: 'West_highland_white_terrier',\n",
       " 53: 'Lhasa',\n",
       " 54: 'Flat_coated_retriever',\n",
       " 55: 'Curly_coated_retriever',\n",
       " 56: 'Golden_retriever',\n",
       " 57: 'Labrador_retriever',\n",
       " 58: 'Chesapeake_bay_retriever',\n",
       " 59: 'German_short_haired_pointer',\n",
       " 60: 'Vizsla',\n",
       " 61: 'English_setter',\n",
       " 62: 'Irish_setter',\n",
       " 63: 'Gordon_setter',\n",
       " 64: 'Brittany_spaniel',\n",
       " 65: 'Clumber',\n",
       " 66: 'English_springer',\n",
       " 67: 'Welsh_springer_spaniel',\n",
       " 68: 'Cocker_spaniel',\n",
       " 69: 'Sussex_spaniel',\n",
       " 70: 'Irish_water_spaniel',\n",
       " 71: 'Kuvasz',\n",
       " 72: 'Schipperke',\n",
       " 73: 'Groenendael',\n",
       " 74: 'Malinois',\n",
       " 75: 'Briard',\n",
       " 76: 'Kelpie',\n",
       " 77: 'Komondor',\n",
       " 78: 'Old_english_sheepdog',\n",
       " 79: 'Shetland_sheepdog',\n",
       " 80: 'Collie',\n",
       " 81: 'Border_collie',\n",
       " 82: 'Bouvier_des_flandres',\n",
       " 83: 'Rottweiler',\n",
       " 84: 'German_shepherd',\n",
       " 85: 'Doberman',\n",
       " 86: 'Miniature_pinscher',\n",
       " 87: 'Greater_swiss_mountain_dog',\n",
       " 88: 'Bernese_mountain_dog',\n",
       " 89: 'Appenzeller',\n",
       " 90: 'Entlebucher',\n",
       " 91: 'Boxer',\n",
       " 92: 'Bull_mastiff',\n",
       " 93: 'Tibetan_mastiff',\n",
       " 94: 'French_bulldog',\n",
       " 95: 'Great_dane',\n",
       " 96: 'Saint_bernard',\n",
       " 97: 'Eskimo_dog',\n",
       " 98: 'Malamute',\n",
       " 99: 'Siberian_husky',\n",
       " 100: 'Affenpinscher',\n",
       " 101: 'Basenji',\n",
       " 102: 'Pug',\n",
       " 103: 'Leonberg',\n",
       " 104: 'Newfoundland',\n",
       " 105: 'Great_pyrenees',\n",
       " 106: 'Samoyed',\n",
       " 107: 'Pomeranian',\n",
       " 108: 'Chow',\n",
       " 109: 'Keeshond',\n",
       " 110: 'Brabancon_griffon',\n",
       " 111: 'Pembroke',\n",
       " 112: 'Cardigan',\n",
       " 113: 'Toy_poodle',\n",
       " 114: 'Miniature_poodle',\n",
       " 115: 'Standard_poodle',\n",
       " 116: 'Mexican_hairless',\n",
       " 117: 'Dingo',\n",
       " 118: 'Dhole',\n",
       " 119: 'African_hunting_dog'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T14:26:11.317001Z",
     "start_time": "2025-10-08T14:26:11.313639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "with open(\"mapping.json\", \"w\") as f:\n",
    "\n",
    "    json.dump(mapping,f)"
   ],
   "id": "89302233c2849c4c",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:24.391174Z",
     "start_time": "2025-10-08T15:42:24.389342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "num_classes = 120"
   ],
   "id": "d8b510beaf430b96",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:24.913270Z",
     "start_time": "2025-10-08T15:42:24.910270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ],
   "id": "97dfa5f5fd49a41d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:47.419502Z",
     "start_time": "2025-10-08T15:42:47.099902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "for param in base.parameters():\n",
    "    param.requires_grad = False  # заморозим фичи\n",
    "\n",
    "in_features = base.fc.in_features\n",
    "base.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "model = base.to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"fc.\"):\n",
    "        param.requires_grad = False"
   ],
   "id": "9f804972d9c03501",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:49.942068Z",
     "start_time": "2025-10-08T15:42:49.857749Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True, map_location=torch.device(\"cuda\")))",
   "id": "fbbd745d902a63ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:54.234849Z",
     "start_time": "2025-10-08T15:42:54.231891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, steps_per_epoch=len(train_loader), epochs=20)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "4e7e717399213b6e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:55.392733Z",
     "start_time": "2025-10-08T15:42:55.389227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(model, criterion, optimizer, device, loader):\n",
    "  model.train()\n",
    "  curr_loss = 0.0\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  for images, labels in tqdm(loader, desc = 'Training'):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    curr_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "  epoch_loss = curr_loss / total\n",
    "  total_loss = correct / total\n",
    "  return epoch_loss, total_loss"
   ],
   "id": "a7a19f1997f553b2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:42:55.753612Z",
     "start_time": "2025-10-08T15:42:55.749392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def val_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    curr_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc= \"val\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            curr_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    epoch_loss = curr_loss/total\n",
    "    epoch_acc = correct/total\n",
    "    return epoch_loss, epoch_acc"
   ],
   "id": "ecdc2f1f9dc03eba",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T18:26:08.164627Z",
     "start_time": "2025-10-07T18:26:08.160626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Размораживаю backbone\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"fc.\"):\n",
    "        param.requires_grad = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ],
   "id": "e4a6958066c5215e",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T19:33:10.923453Z",
     "start_time": "2025-10-07T18:26:08.808074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"start train\")\n",
    "train_losses, val_losses = [], []\n",
    "train_acces, val_acces = [], []\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"____EPOCH____: {epoch}\")\n",
    "    train_loss, train_acc = train_epoch(model, criterion, optimizer, device,  train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_acces.append(train_acc)\n",
    "\n",
    "    val_loss, val_acc = val_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_acces.append(val_acc)\n",
    "\n",
    "    print(f\"train_loss: {train_loss}, train_acc: {train_acc}\")\n",
    "    print(f\"val_loss: {val_loss}, val_acc: {val_acc}\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Best model saved with validation accuracy: {best_val_acc:.4f}\")"
   ],
   "id": "a54f2edcc733d15b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "____EPOCH____: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:30<00:00,  1.72it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.579579288543603, train_acc: 0.8239795918367347\n",
      "val_loss: 0.4711752577645901, val_acc: 0.8551992225461613\n",
      "Best model saved with validation accuracy: 0.8552\n",
      "____EPOCH____: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:34<00:00,  1.67it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.4759619942964919, train_acc: 0.8504008746355685\n",
      "val_loss: 0.4174714866080715, val_acc: 0.8615160349854227\n",
      "Best model saved with validation accuracy: 0.8615\n",
      "____EPOCH____: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:34<00:00,  1.67it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.42924317674108564, train_acc: 0.8624271137026239\n",
      "val_loss: 0.40052746295697256, val_acc: 0.8683187560738581\n",
      "Best model saved with validation accuracy: 0.8683\n",
      "____EPOCH____: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.72it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.4006931742669542, train_acc: 0.872631195335277\n",
      "val_loss: 0.38134749044018884, val_acc: 0.8814382896015549\n",
      "Best model saved with validation accuracy: 0.8814\n",
      "____EPOCH____: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:34<00:00,  1.66it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.36861550277940736, train_acc: 0.8784013605442177\n",
      "val_loss: 0.3744798196068774, val_acc: 0.8707482993197279\n",
      "____EPOCH____: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:40<00:00,  1.61it/s]\n",
      "val: 100%|██████████| 33/33 [00:12<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3493890361054877, train_acc: 0.8844144800777454\n",
      "val_loss: 0.38107524134501075, val_acc: 0.8702623906705539\n",
      "____EPOCH____: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.73it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3296210352255374, train_acc: 0.891399416909621\n",
      "val_loss: 0.37131816809100937, val_acc: 0.8790087463556852\n",
      "____EPOCH____: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.73it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3135487593790069, train_acc: 0.8969873663751214\n",
      "val_loss: 0.35838218350452167, val_acc: 0.8877551020408163\n",
      "Best model saved with validation accuracy: 0.8878\n",
      "____EPOCH____: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.73it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2910494542706928, train_acc: 0.904944120505345\n",
      "val_loss: 0.34580463938509176, val_acc: 0.8926141885325559\n",
      "Best model saved with validation accuracy: 0.8926\n",
      "____EPOCH____: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:34<00:00,  1.67it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2729263093659203, train_acc: 0.9115646258503401\n",
      "val_loss: 0.364964855670118, val_acc: 0.8775510204081632\n",
      "____EPOCH____: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.73it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.25933706520018474, train_acc: 0.9134475218658892\n",
      "val_loss: 0.3553833037151424, val_acc: 0.8824101068999028\n",
      "____EPOCH____: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:35<00:00,  1.66it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.23984988628949092, train_acc: 0.922740524781341\n",
      "val_loss: 0.3491234626445423, val_acc: 0.8867832847424684\n",
      "____EPOCH____: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:39<00:00,  1.61it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.23668691261053318, train_acc: 0.9217079689018465\n",
      "val_loss: 0.33164035541207265, val_acc: 0.8882410106899903\n",
      "____EPOCH____: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:40<00:00,  1.61it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.21694270442479785, train_acc: 0.9281462585034014\n",
      "val_loss: 0.34826831211154036, val_acc: 0.880466472303207\n",
      "____EPOCH____: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:37<00:00,  1.64it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.21574151146689935, train_acc: 0.9289965986394558\n",
      "val_loss: 0.3499103115113095, val_acc: 0.8770651117589893\n",
      "____EPOCH____: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.73it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1994000227707352, train_acc: 0.9336734693877551\n",
      "val_loss: 0.36235078233787454, val_acc: 0.880466472303207\n",
      "____EPOCH____: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:37<00:00,  1.64it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.19055609803273912, train_acc: 0.935617103984451\n",
      "val_loss: 0.3571663820940505, val_acc: 0.8877551020408163\n",
      "____EPOCH____: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:39<00:00,  1.61it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.18006470161548974, train_acc: 0.9410228377065112\n",
      "val_loss: 0.34500170538909697, val_acc: 0.8858114674441205\n",
      "____EPOCH____: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:36<00:00,  1.65it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1725563365093589, train_acc: 0.9434523809523809\n",
      "val_loss: 0.349508328502681, val_acc: 0.8824101068999028\n",
      "____EPOCH____: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:29<00:00,  1.73it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1609069354709082, train_acc: 0.9455174927113703\n",
      "val_loss: 0.3421132321405225, val_acc: 0.8872691933916423\n",
      "____EPOCH____: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:38<00:00,  1.62it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1550906016857909, train_acc: 0.9491010689990281\n",
      "val_loss: 0.3687499892853555, val_acc: 0.8794946550048591\n",
      "____EPOCH____: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:40<00:00,  1.61it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.14641563135287042, train_acc: 0.952259475218659\n",
      "val_loss: 0.3712997711087107, val_acc: 0.8751214771622935\n",
      "____EPOCH____: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:39<00:00,  1.62it/s]\n",
      "val: 100%|██████████| 33/33 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.14270744521978182, train_acc: 0.9518343051506317\n",
      "val_loss: 0.3670051886805988, val_acc: 0.879980563654033\n",
      "____EPOCH____: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 258/258 [02:37<00:00,  1.64it/s]\n",
      "val: 100%|██████████| 33/33 [00:11<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.13378734123486705, train_acc: 0.9548104956268222\n",
      "val_loss: 0.3943253467683078, val_acc: 0.8756073858114675\n",
      "____EPOCH____: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 8/258 [00:04<02:30,  1.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[90]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m      6\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m____EPOCH____: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     train_loss, train_acc = \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m     train_losses.append(train_loss)\n\u001B[32m      9\u001B[39m     train_acces.append(train_acc)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[86]\u001B[39m\u001B[32m, line 6\u001B[39m, in \u001B[36mtrain_epoch\u001B[39m\u001B[34m(model, criterion, optimizer, device, loader)\u001B[39m\n\u001B[32m      4\u001B[39m total = \u001B[32m0\u001B[39m\n\u001B[32m      5\u001B[39m correct = \u001B[32m0\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mTraining\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m  \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m  \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    698\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    699\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    700\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m701\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    702\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    703\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    704\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    705\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    706\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    707\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    755\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    756\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    758\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    759\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.auto_collation:\n\u001B[32m     49\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33m__getitems__\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__:\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     52\u001B[39m         data = [\u001B[38;5;28mself\u001B[39m.dataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001B[39m, in \u001B[36mSubset.__getitems__\u001B[39m\u001B[34m(self, indices)\u001B[39m\n\u001B[32m    418\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dataset.__getitems__([\u001B[38;5;28mself\u001B[39m.indices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m    419\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m420\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[63]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mCustomDataset.__getitem__\u001B[39m\u001B[34m(self, idx)\u001B[39m\n\u001B[32m     19\u001B[39m image = PIL.Image.open(img_path).convert(\u001B[33m\"\u001B[39m\u001B[33mRGB\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform:\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m     image = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[39m, in \u001B[36mCompose.__call__\u001B[39m\u001B[34m(self, img)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transforms:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m         img = \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1370\u001B[39m, in \u001B[36mRandomRotation.forward\u001B[39m\u001B[34m(self, img)\u001B[39m\n\u001B[32m   1368\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1369\u001B[39m         fill = [\u001B[38;5;28mfloat\u001B[39m(f) \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fill]\n\u001B[32m-> \u001B[39m\u001B[32m1370\u001B[39m angle = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdegrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1372\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m F.rotate(img, angle, \u001B[38;5;28mself\u001B[39m.interpolation, \u001B[38;5;28mself\u001B[39m.expand, \u001B[38;5;28mself\u001B[39m.center, fill)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\project\\gpu-env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1352\u001B[39m, in \u001B[36mRandomRotation.get_params\u001B[39m\u001B[34m(degrees)\u001B[39m\n\u001B[32m   1345\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m   1346\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_params\u001B[39m(degrees: List[\u001B[38;5;28mfloat\u001B[39m]) -> \u001B[38;5;28mfloat\u001B[39m:\n\u001B[32m   1347\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Get parameters for ``rotate`` for a random rotation.\u001B[39;00m\n\u001B[32m   1348\u001B[39m \n\u001B[32m   1349\u001B[39m \u001B[33;03m    Returns:\u001B[39;00m\n\u001B[32m   1350\u001B[39m \u001B[33;03m        float: angle parameter to be passed to ``rotate`` for random rotation.\u001B[39;00m\n\u001B[32m   1351\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1352\u001B[39m     angle = \u001B[38;5;28mfloat\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43muniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdegrees\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdegrees\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m.item())\n\u001B[32m   1353\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m angle\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T15:43:36.765566Z",
     "start_time": "2025-10-08T15:43:21.476084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TEST\n",
    "val_epoch(model, test_loader, criterion, device)"
   ],
   "id": "903638bf5abf1a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████| 33/33 [00:15<00:00,  2.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.22577127589834212, 0.9271137026239067)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d68e2ffc49b0387c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
